{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "11da420b-9add-42b0-9c6a-b9f69093bf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from geopy.geocoders import OpenCage\n",
    "from geopy.exc import GeocoderServiceError, GeocoderTimedOut\n",
    "from pandas import json_normalize\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "500446cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing uber dataset\n",
    "df = pd.read_csv('uber_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "edc6d495",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "df['trip_id'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4a148bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_dim = df[['tpep_pickup_datetime','tpep_dropoff_datetime']].reset_index(drop=True)\n",
    "datetime_dim['tpep_pickup_datetime'] = datetime_dim['tpep_pickup_datetime']\n",
    "datetime_dim['pick_hour'] = datetime_dim['tpep_pickup_datetime'].dt.hour\n",
    "datetime_dim['pick_day'] = datetime_dim['tpep_pickup_datetime'].dt.day\n",
    "datetime_dim['pick_month'] = datetime_dim['tpep_pickup_datetime'].dt.month\n",
    "datetime_dim['pick_year'] = datetime_dim['tpep_pickup_datetime'].dt.year\n",
    "datetime_dim['pick_weekday'] = datetime_dim['tpep_pickup_datetime'].dt.weekday\n",
    "\n",
    "datetime_dim['tpep_dropoff_datetime'] = datetime_dim['tpep_dropoff_datetime']\n",
    "datetime_dim['drop_hour'] = datetime_dim['tpep_dropoff_datetime'].dt.hour\n",
    "datetime_dim['drop_day'] = datetime_dim['tpep_dropoff_datetime'].dt.day\n",
    "datetime_dim['drop_month'] = datetime_dim['tpep_dropoff_datetime'].dt.month\n",
    "datetime_dim['drop_year'] = datetime_dim['tpep_dropoff_datetime'].dt.year\n",
    "datetime_dim['drop_weekday'] = datetime_dim['tpep_dropoff_datetime'].dt.weekday\n",
    "datetime_dim['datetime_id'] = datetime_dim.index\n",
    "\n",
    "datetime_dim = datetime_dim[['datetime_id', 'tpep_pickup_datetime', 'pick_hour', 'pick_day', 'pick_month', 'pick_year', 'pick_weekday',\n",
    "                             'tpep_dropoff_datetime', 'drop_hour', 'drop_day', 'drop_month', 'drop_year', 'drop_weekday']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ba67912f",
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_count_dim = df[['passenger_count']].reset_index(drop=True)\n",
    "passenger_count_dim['passenger_count_id'] = passenger_count_dim.index\n",
    "passenger_count_dim = passenger_count_dim[['passenger_count_id','passenger_count']]\n",
    "\n",
    "trip_distance_dim = df[['trip_distance']].reset_index(drop=True)\n",
    "trip_distance_dim['trip_distance_id'] = trip_distance_dim.index\n",
    "trip_distance_dim = trip_distance_dim[['trip_distance_id','trip_distance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fb7c9704",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_code_type = {\n",
    "    1:\"Standard rate\",\n",
    "    2:\"JFK\",\n",
    "    3:\"Newark\",\n",
    "    4:\"Nassau or Westchester\",\n",
    "    5:\"Negotiated fare\",\n",
    "    6:\"Group ride\"\n",
    "}\n",
    "\n",
    "rate_code_dim = df[['RatecodeID']].reset_index(drop=True)\n",
    "rate_code_dim['rate_code_id'] = rate_code_dim.index\n",
    "rate_code_dim['rate_code_name'] = rate_code_dim['RatecodeID'].map(rate_code_type)\n",
    "rate_code_dim = rate_code_dim[['rate_code_id','RatecodeID','rate_code_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8048bdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup_location_dim = df[['pickup_longitude', 'pickup_latitude']].reset_index(drop=True)\n",
    "pickup_location_dim['pickup_location_id'] = pickup_location_dim.index\n",
    "pickup_location_dim = pickup_location_dim[['pickup_location_id','pickup_latitude','pickup_longitude']] \n",
    "dropoff_location_dim = df[['dropoff_longitude', 'dropoff_latitude']].reset_index(drop=True)\n",
    "dropoff_location_dim['dropoff_location_id'] = dropoff_location_dim.index\n",
    "dropoff_location_dim = dropoff_location_dim[['dropoff_location_id','dropoff_latitude','dropoff_longitude']]\n",
    "\n",
    "pickup_location_dim = pickup_location_dim.head(5)\n",
    "dropoff_location_dim = dropoff_location_dim.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5fab92a8-1acd-46ce-a397-74941a9d8881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_geocode(latitude, longitude, api_key):\n",
    "    try:\n",
    "        geolocator = OpenCage(api_key)\n",
    "        location = geolocator.reverse((latitude, longitude), exactly_one=True)\n",
    "        if location:\n",
    "            address = location.address\n",
    "            location_details = location.raw\n",
    "            return address, location_details\n",
    "        else:\n",
    "            return None, None\n",
    "    except GeocoderTimedOut:\n",
    "        print(\"Error: Geocoding service timed out\")\n",
    "        return None, None\n",
    "    except GeocoderServiceError as e:\n",
    "        print(f\"Error: Geocoding service error - {e}\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None, None\n",
    "\n",
    "api_key = ''\n",
    "\n",
    "# Define a wrapper function to pass the API key to reverse_geocode and handle the return values\n",
    "def apply_reverse_pickup_geocode(row):\n",
    "    address, location_details = reverse_geocode(row['pickup_latitude'], row['pickup_longitude'], api_key)\n",
    "    return pd.Series([address, location_details])\n",
    "\n",
    "# Apply the function to each row in the DataFrame and expand the result into two new columns\n",
    "pickup_location_dim[['address', 'location_details']] = pickup_location_dim.apply(apply_reverse_pickup_geocode, axis=1)\n",
    "# Extract location_details JSON into a DataFrame\n",
    "location_details_df = json_normalize(pickup_location_dim['location_details'])\n",
    "pickup_location_dim = pickup_location_dim.join(location_details_df)\n",
    "# Print the updated DataFrame\n",
    "\n",
    "# Define a wrapper function to pass the API key to reverse_geocode and handle the return values\n",
    "def apply_reverse_dropoff_geocode(row):\n",
    "    address, location_details = reverse_geocode(row['dropoff_latitude'], row['dropoff_longitude'], api_key)\n",
    "    return pd.Series([address, location_details])\n",
    "\n",
    "# Apply the function to each row in the DataFrame and expand the result into two new columns\n",
    "dropoff_location_dim[['address', 'location_details']] = dropoff_location_dim.apply(apply_reverse_dropoff_geocode, axis=1)\n",
    "# Extract location_details JSON into a DataFrame\n",
    "location_details_df = json_normalize(dropoff_location_dim['location_details'])\n",
    "dropoff_location_dim = dropoff_location_dim.join(location_details_df)\n",
    "# Print the updated DataFrame\n",
    "\n",
    "dropoff_location_dim = dropoff_location_dim.drop(columns=['location_details'])\n",
    "pickup_location_dim = pickup_location_dim.drop(columns=['location_details'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bfb04993",
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_type_name = {\n",
    "    1:\"Credit card\",\n",
    "    2:\"Cash\",\n",
    "    3:\"No charge\",\n",
    "    4:\"Dispute\",\n",
    "    5:\"Unknown\",\n",
    "    6:\"Voided trip\"\n",
    "}\n",
    "payment_type_dim = df[['payment_type']].reset_index(drop=True)\n",
    "payment_type_dim['payment_type_id'] = payment_type_dim.index\n",
    "payment_type_dim['payment_type_name'] = payment_type_dim['payment_type'].map(payment_type_name)\n",
    "payment_type_dim = payment_type_dim[['payment_type_id','payment_type','payment_type_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e747865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_table = df.merge(passenger_count_dim, left_on='trip_id', right_on='passenger_count_id') \\\n",
    "             .merge(trip_distance_dim, left_on='trip_id', right_on='trip_distance_id') \\\n",
    "             .merge(rate_code_dim, left_on='trip_id', right_on='rate_code_id') \\\n",
    "             .merge(pickup_location_dim, left_on='trip_id', right_on='pickup_location_id') \\\n",
    "             .merge(dropoff_location_dim, left_on='trip_id', right_on='dropoff_location_id')\\\n",
    "             .merge(datetime_dim, left_on='trip_id', right_on='datetime_id') \\\n",
    "             .merge(payment_type_dim, left_on='trip_id', right_on='payment_type_id') \\\n",
    "             [['trip_id','VendorID', 'datetime_id', 'passenger_count_id',\n",
    "               'trip_distance_id', 'rate_code_id', 'store_and_fwd_flag', 'pickup_location_id', 'dropoff_location_id',\n",
    "               'payment_type_id', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount',\n",
    "               'improvement_surcharge', 'total_amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a0d9a74c-22b8-4625-aca3-662f81cad6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect('UberDataWarehouse.db')\n",
    "\n",
    "dropoff_location_dim = dropoff_location_dim.applymap(str)\n",
    "pickup_location_dim = pickup_location_dim.applymap(str)\n",
    "\n",
    "# Write the DataFrames to SQLite Tables\n",
    "fact_table.to_sql('fact_table', conn, if_exists='replace', index=False)\n",
    "datetime_dim.to_sql('datetime_dim', conn, if_exists='replace', index=False)\n",
    "dropoff_location_dim.to_sql('dropoff_location_dim', conn, if_exists='replace', index=False)\n",
    "passenger_count_dim.to_sql('passenger_count_dim', conn, if_exists='replace', index=False)\n",
    "payment_type_dim.to_sql('payment_type_dim', conn, if_exists='replace', index=False)\n",
    "pickup_location_dim.to_sql('pickup_location_dim', conn, if_exists='replace', index=False)\n",
    "rate_code_dim.to_sql('rate_code_dim', conn, if_exists='replace', index=False)\n",
    "trip_distance_dim.to_sql('trip_distance_dim', conn, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
